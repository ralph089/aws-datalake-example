# Custom log4j configuration for local Glue job development
# This configuration reduces Spark verbosity while preserving application logs

# Set root logger to WARN level with console appender
log4j.rootLogger=WARN, console

# Console appender configuration
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.out
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# Spark framework loggers - set to WARN to reduce verbosity
log4j.logger.org.apache.spark=WARN
log4j.logger.org.spark_project=WARN
log4j.logger.org.apache.hadoop=WARN
log4j.logger.io.netty=WARN
log4j.logger.org.apache.zookeeper=WARN
log4j.logger.org.apache.parquet=WARN

# AWS Glue specific loggers
log4j.logger.com.amazon.ws.emr=WARN
log4j.logger.com.amazonaws=WARN

# Reduce verbosity for specific noisy components
log4j.logger.org.apache.spark.sql.catalyst.expressions.codegen=WARN
log4j.logger.org.apache.spark.sql.execution.datasources=WARN
log4j.logger.org.apache.spark.storage=WARN
log4j.logger.org.apache.spark.scheduler=WARN
log4j.logger.org.apache.spark.network=WARN

# Keep Python application logs at INFO level
# Our application uses Python logging which integrates with this config
log4j.logger.py4j=INFO

# Special handling for important events we want to see
log4j.logger.org.apache.spark.SparkContext=INFO
log4j.logger.org.apache.spark.sql.SparkSession=INFO

# Show errors and warnings from all components
log4j.logger.root=WARN